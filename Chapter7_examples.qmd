---
title: "Chapter7brms"
format: pdf
editor: visual
---

## Chapter 7

Examples of CV, PSIS-loo, and WAIC

```{r, message=FALSE,warning=FALSE}
library(tidyverse)
#library(rethinking)
library(brms)
library(tidybayes)
options("brms.backend" = "cmdstanr")
options("brms.file_refit" = "always")

```

To start I'll run some models from chapter 6.

Here's a section from Chapter 6 in Solomon Kurtz's brms version of rethinking.

## Post-treatment bias

It helped me understand the next example by mapping out the sequence of events McElreath described in the second paragraph:

-   seed and sprout plants
-   measure heights
-   apply different antifungal soil treatments (i.e., the experimental manipulation)
-   measure (a) the heights and (b) the presence of fungus

Based on the design, let's simulate our data.

```{r}
# how many plants would you like?
n <- 100

set.seed(71)
d <- 
  tibble(h0        = rnorm(n, mean = 10, sd = 2), 
         treatment = rep(0:1, each = n / 2),
         fungus    = rbinom(n, size = 1, prob = .5 - treatment * 0.4),
         h1        = h0 + rnorm(n, mean = 5 - 3 * fungus, sd = 1))
```

We'll use `head()` to peek at the data.

```{r}
d %>%
  head()
```

And here's a quick summary with `tidybayes::mean_qi()`.

```{r}
d %>% 
  pivot_longer(everything()) %>% 
  group_by(name) %>% 
  mean_qi(.width = .89) %>% 
  mutate_if(is.double, round, digits = 2)
```

If you want to make those cute mini histograms, go back and check out our custom `histospark()` code from \[Chapter 4\]\[Geocentric Models\].

### A prior is born.

Let's take a look at the $p \sim \operatorname{Log-Normal}(0, 0.25)$ prior distribution.

```{r, fig.width = 6, fig.height = 3.25}
set.seed(6)

# simulate
sim_p <-
  tibble(sim_p = rlnorm(1e4, meanlog = 0, sdlog = 0.25)) 

# wrangle
sim_p %>% 
  mutate(`exp(sim_p)` = exp(sim_p)) %>%
  gather() %>% 
  
  # plot
  ggplot(aes(x = value)) +
  geom_density(fill = "steelblue") +
  scale_x_continuous(breaks = c(0, .5, 1, 1.5, 2, 3, 5)) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = c(0, 6)) +
  theme(panel.grid.minor.x = element_blank()) +
  facet_wrap(~ key, scale = "free_y", ncol = 1)
```

Summarize.

```{r}
sim_p %>% 
  mutate(`exp(sim_p)` = exp(sim_p)) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>% 
  mean_qi(.width = .89) %>% 
  mutate_if(is.double, round, digits = 2)
```

"This prior expects anything from 40% shrinkage up to 50% growth" (p. 172). So then, our initial statistical model will follow the form

\begin{align*}
h_{1i} & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i  & = h_{0i} \times p \\
p      & \sim \operatorname{Log-Normal}(0, 0.25) \\
\sigma & \sim \operatorname{Exponential}(1).
\end{align*}

Let's fit that model.

```{r b6.6, message=FALSE,warning=FALSE}
b6.6 <- 
  brm(data = d, 
      family = gaussian,
      h1 ~ 0 + h0,
      prior = c(prior(lognormal(0, 0.25), class = b, lb = 0),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 6,
      file = "fits/b06.06")

```

Note our use of the `lb` argument to set the lower bound for the prior on $p$. Anyway, behold the summary.

```{r}
print(b6.6)
```

So then, the expectation is an increase of about `r round((fixef(b6.6)[1] - 1) * 100, 0)` percent relative to $h_0$. But this isn't the best model. We're leaving important predictors on the table. Our updated model follows the form

\begin{align*}
h_{1i}  & \sim  \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i   & = h_{0,i} \times p \\
p       & = \alpha + \beta_1 \text{treatment}_i + \beta_2 \text{fungus}_i \\
\alpha  & \sim \operatorname{Log-Normal}(0, 0.25) \\
\beta_1 & \sim \operatorname{Normal}(0, 0.5) \\
\beta_2 & \sim \operatorname{Normal}(0, 0.5) \\
\sigma  & \sim \operatorname{Exponential}(1).
\end{align*}

That is, the "proportion of growth $p$ is now a function of the predictor variables" (p. 172). Although we will fit the equivalent of McElreath's model in **brms**, I'm not aware that we can translate it directly into conventional **brms** syntax. But take a look at the critical two lines from above:

\begin{align*}
\mu_i & = h_{0,i} \times p \\
p     & = \alpha + \beta_1 \text{treatment}_i + \beta_2 \text{fungus}_i. \\
\end{align*}

With just a little algebra, we can re-express that as

$$\mu_i = h_{0i} \times (\alpha + \beta_1 \text{treatment}_i + \beta_2 \text{fungus}_i).$$

With **brms**, we fit models like that using the [non-linear syntax](https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html) [@Bürkner2022Non_linear], which we briefly introduced in \[Section 4.4.2.1\]\[Overthinking: Logs and exps, oh my.\] and \[Section 5.3.2\]\[Many categories.\]. Yes friends, it's now time we discuss the non-linear **brms** syntax in detail. Bur first, here's what it looks like for `b6.7`.

```{r b6.7}
b6.7 <- 
  brm(data = d, 
      family = gaussian,
      bf(h1 ~ h0 * (a + t * treatment + f * fungus),
         a + t + f ~ 1,
         nl = TRUE),
      prior = c(prior(lognormal(0, 0.2), nlpar = a, lb = 0),
                prior(normal(0, 0.5), nlpar = t),
                prior(normal(0, 0.5), nlpar = f),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 6,
      file = "fits/b06.07")
```

To explain what's going on with our `formula`syntax, it's probably best to quote Bürkner's [-@Bürkner2022Non_linear] [vignette](https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html) at length:

> When looking at the above code, the first thing that becomes obvious is that we changed the `formula` syntax to display the non-linear formula including predictors (i.e., \[`h0`, `treatment`, and `fungus`\]) and parameters (i.e., \[`a`, `t`, and `f`\]) wrapped in a call to \[the `bf()` function\]. This stands in contrast to classical **R** formulas, where only predictors are given and parameters are implicit. The argument \[`a + t + f ~ 1`\] serves two purposes. First, it provides information, which variables in `formula` are parameters, and second, it specifies the linear predictor terms for each parameter. In fact, we should think of non-linear parameters as placeholders for linear predictor terms rather than as parameters themselves (see also the following examples). In the present case, we have no further variables to predict \[`a`, `t`, and `f`\] and thus we just fit intercepts that represent our estimates of \[$\alpha$, $t$, and $f$\]. The formula \[`a + t + f ~ 1`\] is a short form of\[`a ~ 1, t ~ 1, f ~ 1`\] that can be used if multiple non-linear parameters share the same formula. Setting `nl = TRUE` tells **brms** that the formula should be treated as non-linear.

> In contrast to generalized linear models, priors on population-level parameters (i.e., 'fixed effects') are often mandatory to identify a non-linear model. Thus, **brms** requires the user to explicitly specify these priors. In the present example, we used a \[`lognormal(0, 0.2)` prior on (the population-level intercept of) `a`, while we used a `normal(0, 0.5)` prior on both (population-level intercepts of) `t` and `f`\]. Setting priors is a non-trivial task in all kinds of models, especially in non-linear models, so you should always invest some time to think of appropriate priors. Quite often, you may be forced to change your priors after fitting a non-linear model for the first time, when you observe different MCMC chains converging to different posterior regions. This is a clear sign of an identification problem and one solution is to set stronger (i.e., more narrow) priors. (**emphasis** in the original)

Let's see what we've done.

```{r}
print(b6.7)
```

All in all, it looks like we did a good job matching up McElreath's results. The posterior doesn't, however, match up well with the way we generated the data...

### Blocked by consequence.

To measure the treatment effect properly, we should omit `fungus` from the model. This leaves us with the equation

\begin{align*}
h_{1i}  & \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i   & = h_{0i} \times (\alpha + \beta_1 \text{treatment}_i) \\
\alpha  & \sim \operatorname{Log-Normal}(0, 0.25) \\
\beta_1 & \sim \operatorname{Normal}(0, 0.5) \\
\sigma  & \sim \operatorname{Exponential}(1).
\end{align*}

Fit this model with the non-linear syntax, too.

```{r b6.8}
b6.8 <- 
  brm(data = d, 
      family = gaussian,
      bf(h1 ~ h0 * (a + t * treatment),
         a + t ~ 1,
         nl = TRUE),
      prior = c(prior(lognormal(0, 0.2), nlpar = a, lb = 0),
                prior(normal(0, 0.5), nlpar = t),
                prior(exponential(1), class = sigma)),
      iter = 2000, warmup = 1000, chains = 4, cores = 4,
      seed = 6,
      file = "fits/b06.08")
```

```{r}



```

The `echo: false` option disables the printing of code (only output is displayed).
